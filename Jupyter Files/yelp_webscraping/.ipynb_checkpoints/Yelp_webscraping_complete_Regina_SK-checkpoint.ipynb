{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706d84f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing dependencies/libraries\n",
    "\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42fd519",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing approach. Instead of going through several city/locations in a for loop, we will scrape per city/location.\n",
    "#Scraping per city/location saves allows us to use the data as soon as its scraped.\n",
    "\n",
    "# #ON\n",
    "# location_on = [\"greater-sudbury\", \"hamilton\", \"kingston\", \"london\", \"niagara-falls\",\n",
    "#             \"ottawa\", \"toronto\", \"windsor\", \"kitchener\", \"peterborough\", \n",
    "#             \"sault-ste-marie\", \"thunder-bay\"]\n",
    "\n",
    "# #AB\n",
    "# location_ab = [\"edmonton\", \"calgary\", \"lethbridge\", \"red-deer\"]\n",
    "\n",
    "# #NS\n",
    "# location_ns = [\"halifax\"]\n",
    "\n",
    "# #QC\n",
    "# location_qc = [\"montreal\", \"sherbrooke\", \"trois-rivieres\", \"quebec\"]\n",
    "\n",
    "# #BC\n",
    "# location_bc = [\"vancouver\", \"victoria\"]\n",
    "\n",
    "# #MB\n",
    "# location_mb = [\"winnipeg\"]\n",
    "\n",
    "#------ADJUST LOCATION VARIABLE------\n",
    "location_sk = ['regina']\n",
    "prov = ['sk']\n",
    "\n",
    "#Yelp shows 10 restaurants (not including sponsored ones) per page. \n",
    "#The web page can be changed by manipulating the number at after the'start=' line of the url.\n",
    "pages = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde3c408",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape links for each restaurant from the yelp's front page\n",
    "\n",
    "#Empty lists to hold the values\n",
    "restaurant_links = []\n",
    "\n",
    "#Webscraping for restaurant links\n",
    "browser = Browser('chrome')\n",
    "\n",
    "#This for loop changes the page on the url\n",
    "#------ADJUST LOCATION VARIABLE------\n",
    "for loc in location_sk:\n",
    "    \n",
    "    #This for loop changes the location of the url\n",
    "    for page in pages:  \n",
    "        \n",
    "        url = f'https://www.yelp.com/search?find_desc=Restaurants&find_loc={loc}%2C+{prov}&start={page}'\n",
    "        browser.visit(url)\n",
    "        html = browser.html\n",
    "        soup_obj = soup(html, 'html.parser')\n",
    "        \n",
    "        res_info = []\n",
    "        res_info = soup_obj.find_all(\"div\", class_ = \"businessName__09f24__EYSZE display--inline-block__09f24__fEDiJ border-color--default__09f24__NPAKY\")\n",
    "        time.sleep(3)\n",
    "        \n",
    "        for info in res_info:\n",
    "            \n",
    "            try:\n",
    "                target = info.a['href']\n",
    "                restaurant_links.append(target)\n",
    "\n",
    "            except:\n",
    "                restaurant_links.append(\"No data or change code\")    \n",
    "                \n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e6d562",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visually checking scraping results\n",
    "restaurant_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aba6a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visually checking scraping results\n",
    "len(restaurant_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e4f351",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Extracting address from each link, using the link in the list restaurant_links\n",
    "\n",
    "#Setting up a counter to keep track of progress; this code takes about ~30 mins to run\n",
    "counter = 1\n",
    "\n",
    "#Setting up empty lists\n",
    "names = []\n",
    "# total_reviews = []\n",
    "# all_information = []\n",
    "restaurant_address = []\n",
    "\n",
    "#Extracting restaurant name and address from restaurant's business page\n",
    "browser = Browser('chrome')\n",
    "\n",
    "for link in restaurant_links:\n",
    "       \n",
    "    #Visiting the resturant's Yelp page \n",
    "    base_url = \"https://www.yelp.com\"\n",
    "    res_url = f\"https://www.yelp.com{link}\"\n",
    "\n",
    "    browser.visit(res_url)\n",
    "\n",
    "    html = browser.html\n",
    "\n",
    "    soup_obj = soup(html, 'html.parser')\n",
    "    time.sleep(3)\n",
    "    \n",
    "    #Extracting name\n",
    "    name = soup_obj.find('h1', class_ = \"css-1se8maq\")\n",
    "    if name:\n",
    "        data = name.text\n",
    "        names.append(data)\n",
    "\n",
    "    else:\n",
    "        names.append(\"No data or change code\")\n",
    "\n",
    "\n",
    "#     reviews = soup_obj.find('a', class_ = \"css-19v1rkv\")\n",
    "#     if reviews:\n",
    "#         data2 = reviews.text\n",
    "#         total_reviews.append(data2)\n",
    "#         print(data2)\n",
    "#         print(\"------\")\n",
    "#     else:\n",
    "#         print(\"No data or change code\")\n",
    "\n",
    "#     information = soup_obj.find_all('span', class_ = \"css-1fdy0l5\")\n",
    "#     if information:\n",
    "#         for info in information:\n",
    "#             all_information.append(info.text)\n",
    "#             print(info.text)\n",
    "\n",
    "#     else:\n",
    "#         print(\"No data or change code\")\n",
    "    \n",
    "    #Extracting address\n",
    "    address = soup_obj.find('p', class_ = \"css-qyp8bo\")\n",
    "\n",
    "    if address:\n",
    "        data3 = address.text\n",
    "        restaurant_address.append(data3)\n",
    "\n",
    "    else:\n",
    "        restaurant_address.append(\"No data or change code\")\n",
    "        \n",
    "    print(f'Link # {counter}')\n",
    "    counter += 1\n",
    "\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89005869",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visually checking scraping results\n",
    "restaurant_address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff481c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visually checking scraping results\n",
    "len(restaurant_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6e38b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting and joining restaurant name and address scraped from business page\n",
    "test_df = pd.DataFrame({\n",
    "    \"restaurant_name\" : names,\n",
    "    \"address\" : restaurant_address\n",
    "})\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b26cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping information from Yelp's front page\n",
    "\n",
    "#Empty lists to hold the values\n",
    "names_fps = []\n",
    "price_range = []\n",
    "ratings = []\n",
    "total_reviews = []\n",
    "category = []\n",
    "location = []\n",
    "province = []\n",
    "\n",
    "#Web scraping\n",
    "browser = Browser('chrome')\n",
    "\n",
    "#This for loop changes the page on the url\n",
    "#------ADJUST LOCATION VARIABLE------\n",
    "for loc in location_mb:\n",
    "    \n",
    "    #This for loop changes the location of the url\n",
    "    for page in pages:  \n",
    "        \n",
    "        url = f'https://www.yelp.com/search?find_desc=Restaurants&find_loc={loc}%2C+{prov}&start={page}'\n",
    "        browser.visit(url)\n",
    "        html = browser.html\n",
    "        soup_obj = soup(html, 'html.parser')      \n",
    "        \n",
    "        #Scraping the div that contains the target elements\n",
    "        res_info = []    \n",
    "        res_info = soup_obj.find_all(\"div\", class_ = \"container__09f24__mpR8_ hoverable__09f24__wQ_on border-color--default__09f24__NPAKY\")\n",
    "        time.sleep(3)\n",
    "        \n",
    "        #Extracting the target elements\n",
    "        for info in res_info:\n",
    "            #Extracting restaurant name\n",
    "            try:\n",
    "                name = info.find(\"a\", class_ = \"css-19v1rkv\").text\n",
    "                names_fps.append(name)\n",
    "            except:\n",
    "                names_fps.append(\"No data or change the code\")\n",
    "              \n",
    "            #Extracting price range\n",
    "            if info.find(\"span\", {\"class\":\"priceRange__09f24__mmOuH css-chan6m\"}):\n",
    "                prc_range = info.find(\"span\", {\"class\":\"priceRange__09f24__mmOuH css-chan6m\"}).text\n",
    "                price_range.append(prc_range)\n",
    "            elif info.find(\"span\", {\"class\":\"priceRange__09f24__mmOuH css-1s7bx9e\"}):\n",
    "                prc_range = info.find(\"span\", {\"class\":\"priceRange__09f24__mmOuH css-1s7bx9e\"}).text\n",
    "                price_range.append(prc_range)\n",
    "            else:\n",
    "                price_range.append(\"No data or change the code\")\n",
    "            \n",
    "            #Extracting ratings\n",
    "            try:\n",
    "                rati = info.find(\"span\", {\"class\":\"css-gutk1c\"}).text\n",
    "                ratings.append(rati)\n",
    "            except:\n",
    "                ratings.append(\"No data or change the code\")\n",
    "            \n",
    "            #Extracting total number of reviews\n",
    "            #Yelp seems to have a different class for reviews in Montreal's restaurant front page, so code is adjusted\n",
    "            try: #---------------------> OG code\n",
    "                revs = info.find(\"span\", {\"class\":\"css-chan6m\"}).text\n",
    "                total_reviews.append(revs)\n",
    "            except:\n",
    "                total_reviews.append(\"No data or change the code\")\n",
    "            #--------------> option 2    \n",
    "#             if info.find(\"span\", {\"class\":\"css-8xcil9\"}):\n",
    "#                 revs = info.find(\"span\", {\"class\":\"css-8xcil9\"}).text\n",
    "#                 total_reviews.append(revs)\n",
    "#             elif info.find(\"span\", {\"class\":\"css-chan6m\"}):\n",
    "#                 revs = info.find(\"span\", {\"class\":\"css-chan6m\"}).text\n",
    "#                 total_reviews.append(revs)\n",
    "#             else:\n",
    "#                 total_reviews.append(\"No data or change the code\")\n",
    "            \n",
    "            \n",
    "            #Extracting category\n",
    "            try:\n",
    "                categ = info.find(\"span\", {\"class\":\"css-11bijt4\"}).text\n",
    "                category.append(categ)\n",
    "            except:\n",
    "                category.append(\"No data or change the code\")\n",
    "            \n",
    "            #Assigning location and province.\n",
    "            #------ADJUST PROVINCE TO APPEND------\n",
    "            location.append(loc)\n",
    "            province.append(\"MB\")\n",
    "\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74dc923",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Visually checking scraping results\n",
    "total_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d6374c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visually checking scraping results\n",
    "len(total_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dfb980",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Converting and joining data scraped from front page\n",
    "test_df2 = pd.DataFrame({\n",
    "    \"restaurant_name\" : names_fps,\n",
    "    \"price_range\" : price_range,\n",
    "    \"rating\" : ratings,\n",
    "    \"total_reviews\" : total_reviews,\n",
    "    \"category\" : category,\n",
    "    \"location\" : location,\n",
    "    \"province\" : province\n",
    "})\n",
    "\n",
    "test_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b98c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging business page and front page dataframe\n",
    "merged_df = pd.merge(test_df2, test_df, on=\"restaurant_name\", how = \"left\")\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b91b76f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Cleaning merged dataframe\n",
    "merged_df.drop_duplicates()\n",
    "merged_df.replace('No data or change the code', np.nan, inplace = True)\n",
    "merged_df.dropna(inplace = True)\n",
    "merged_df = merged_df.reset_index(drop = True)\n",
    "merged_df['total_reviews'] = merged_df['total_reviews'].str.replace(r'[\\(\\) reviews]', '', regex=True)\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3fb720",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visually checking dataframe\n",
    "data_checking = merged_df['restaurant_name'].value_counts()\n",
    "data_checking.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583d92af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Visually checking dataframe\n",
    "#------ADJUST VALUE TO BE CHECKED------\n",
    "merged_df[merged_df.eq('OEB Breakfast').any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58597593",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Further cleaning dataframe, each restaurant to be dropped were visually inspected through their Yelp business page\n",
    "merged_df.drop([3, 4, 5, 6, 7, 8, 9], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f8abc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visually checking dataframe\n",
    "data_checking2 = merged_df['restaurant_name'].value_counts()\n",
    "data_checking2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae96fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making an output csv\n",
    "#------ADJUST CSV NAME------\n",
    "merged_df.to_csv(\"yelp_winnipeg_mb_complete.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea0dc9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
